{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import MeCab\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from gensim.models import word2vec\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm, tqdm_pandas, tqdm_notebook\n",
    "import time\n",
    "tqdm.pandas(tqdm_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "roomba_df = pd.read_csv('../data/roomba.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ちょっと前処理\n",
    "roomba_df = roomba_df[['is_positive', 'tweet_text']]\n",
    "roomba_df.columns = ['label', 'text']\n",
    "roomba_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wakati_text(text):\n",
    "    tagger = MeCab.Tagger('-Owakati')\n",
    "    wakati_text = tagger.parse(text).strip()\n",
    "    return wakati_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1288/1288 [00:00<00:00, 2688.32it/s]\n"
     ]
    }
   ],
   "source": [
    "roomba_df['wakati_text'] = roomba_df.text.progress_apply(get_wakati_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = roomba_df.label.values\n",
    "accs_dict = {}\n",
    "elapsed_times_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_get_oof_accuracies(X, y, params):\n",
    "    START_TIME = time.time()\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    accuracies = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
    "        print(f'Start: fold {i+1}')\n",
    "        X_train, y_train = X[train_index, :], y[train_index]\n",
    "        X_valid, y_valid = X[valid_index, :], y[valid_index]\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=(X_valid, y_valid),\n",
    "            eval_metric='auc',\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=100\n",
    "        )\n",
    "        y_pred = model.predict(X_valid)\n",
    "        accuracy = accuracy_score(y_valid, y_pred)\n",
    "        print(f'Accuracy is {accuracy} \\n')\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    elapsed_time = time.time() - START_TIME\n",
    "    print(f'Elapsed time is {elapsed_time}.')\n",
    "    return accuracies, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'n_estimators': 10000,\n",
    "    'random_seed': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "X = vectorizer.fit_transform(roomba_df.wakati_text.values)\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 4331)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.770763\tvalid_0's binary_logloss: 0.623451\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.778346\tvalid_0's binary_logloss: 0.558682\n",
      "Accuracy is 0.7131782945736435 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.809641\tvalid_0's binary_logloss: 0.543696\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.814275\tvalid_0's binary_logloss: 0.515239\n",
      "Accuracy is 0.7325581395348837 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.820805\tvalid_0's binary_logloss: 0.5511\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.822972\tvalid_0's binary_logloss: 0.515779\n",
      "Accuracy is 0.7325581395348837 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.793593\tvalid_0's binary_logloss: 0.582118\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.784796\tvalid_0's binary_logloss: 0.54284\n",
      "Accuracy is 0.688715953307393 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.788436\tvalid_0's binary_logloss: 0.587875\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.786616\tvalid_0's binary_logloss: 0.553713\n",
      "Accuracy is 0.7276264591439688 \n",
      "\n",
      "Elapsed time is 0.5357050895690918.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['bow'], elapsed_times_dict['bow'] = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW+TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd = TruncatedSVD(n_components=100)\n",
    "X_reduced = tsvd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.78617\tvalid_0's binary_logloss: 0.616381\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.784726\tvalid_0's binary_logloss: 0.563807\n",
      "Accuracy is 0.689922480620155 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.761555\tvalid_0's binary_logloss: 0.659433\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.755477\tvalid_0's binary_logloss: 0.591858\n",
      "Accuracy is 0.6666666666666666 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.817646\tvalid_0's binary_logloss: 0.547301\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.808438\tvalid_0's binary_logloss: 0.530274\n",
      "Accuracy is 0.7403100775193798 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.805424\tvalid_0's binary_logloss: 0.550697\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.804696\tvalid_0's binary_logloss: 0.537072\n",
      "Accuracy is 0.7159533073929961 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.782551\tvalid_0's binary_logloss: 0.603811\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.767201\tvalid_0's binary_logloss: 0.569996\n",
      "Accuracy is 0.7042801556420234 \n",
      "\n",
      "Elapsed time is 1.5540494918823242.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['bow_tsvd'], elapsed_times_dict['bow_tsvd'] = train_and_get_oof_accuracies(X_reduced, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True, token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "X = vectorizer.fit_transform(roomba_df.wakati_text.values)\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 4331)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.766791\tvalid_0's binary_logloss: 0.65022\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.774254\tvalid_0's binary_logloss: 0.559433\n",
      "Accuracy is 0.6821705426356589 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.811928\tvalid_0's binary_logloss: 0.579482\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.8026\tvalid_0's binary_logloss: 0.526978\n",
      "Accuracy is 0.7364341085271318 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.820234\tvalid_0's binary_logloss: 0.572954\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.819842\tvalid_0's binary_logloss: 0.51058\n",
      "Accuracy is 0.7558139534883721 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.782702\tvalid_0's binary_logloss: 0.618418\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.79153\tvalid_0's binary_logloss: 0.54081\n",
      "Accuracy is 0.7120622568093385 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.777909\tvalid_0's binary_logloss: 0.617729\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.794776\tvalid_0's binary_logloss: 0.549089\n",
      "Accuracy is 0.7198443579766537 \n",
      "\n",
      "Elapsed time is 0.6828150749206543.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['tfidf'], elapsed_times_dict['tfidf'] = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF+TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd = TruncatedSVD(n_components=100)\n",
    "X_reduced = tsvd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.841237\tvalid_0's binary_logloss: 0.556817\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.839552\tvalid_0's binary_logloss: 0.496335\n",
      "Accuracy is 0.7596899224806202 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.817525\tvalid_0's binary_logloss: 0.561323\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.809882\tvalid_0's binary_logloss: 0.529988\n",
      "Accuracy is 0.7015503875968992 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.854899\tvalid_0's binary_logloss: 0.496176\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.859052\tvalid_0's binary_logloss: 0.462638\n",
      "Accuracy is 0.7713178294573644 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.849047\tvalid_0's binary_logloss: 0.521497\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.843162\tvalid_0's binary_logloss: 0.504865\n",
      "Accuracy is 0.7509727626459144 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.853962\tvalid_0's binary_logloss: 0.489774\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.851353\tvalid_0's binary_logloss: 0.477349\n",
      "Accuracy is 0.7665369649805448 \n",
      "\n",
      "Elapsed time is 1.667398452758789.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['tfidf_tsvd'], elapsed_times_dict['tfidf_tsvd']  = train_and_get_oof_accuracies(X_reduced, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec -mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [doc.split() for doc in roomba_df.wakati_text.values]\n",
    "model_w2v = word2vec.Word2Vec(corpus, size=300, min_count=20, window=10)\n",
    "model_w2v.save('../model/roomba_w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_mean_vector(doc, model):\n",
    "    doc_vector = np.zeros(model.vector_size)\n",
    "    words = doc.split()\n",
    "    word_cnt = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_vector = model.wv[word]\n",
    "            doc_vector += word_vector\n",
    "            word_cnt += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "    doc_vector /= word_cnt\n",
    "    return doc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c603d3ce31649289ba3760d86187ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(roomba_df), model_w2v.wv.vector_size))\n",
    "\n",
    "for i, doc in tqdm_notebook(enumerate(roomba_df.wakati_text.values)):\n",
    "    X[i, :] = get_doc_mean_vector(doc, model_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.674862\tvalid_0's binary_logloss: 0.769171\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.656084\tvalid_0's binary_logloss: 0.659719\n",
      "Accuracy is 0.6201550387596899 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.655152\tvalid_0's binary_logloss: 0.781665\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.613325\tvalid_0's binary_logloss: 0.674009\n",
      "Accuracy is 0.6124031007751938 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.675674\tvalid_0's binary_logloss: 0.754755\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.668272\tvalid_0's binary_logloss: 0.642768\n",
      "Accuracy is 0.6046511627906976 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.667395\tvalid_0's binary_logloss: 0.785201\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.656413\tvalid_0's binary_logloss: 0.650679\n",
      "Accuracy is 0.603112840466926 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.646159\tvalid_0's binary_logloss: 0.812507\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.627533\tvalid_0's binary_logloss: 0.669738\n",
      "Accuracy is 0.5836575875486382 \n",
      "\n",
      "Elapsed time is 3.201961040496826.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['w2v_mean'], elapsed_times_dict['w2v_mean']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWEM-MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_swem_max_vector(doc, model):\n",
    "    words = doc.split()\n",
    "    word_cnt = 0\n",
    "    vector_size = model.vector_size\n",
    "    \n",
    "    doc_vector = np.zeros((len(words), vector_size))\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        try:\n",
    "            word_vector = model.wv[word]\n",
    "        except KeyError:\n",
    "            word_vector = np.zeros(vector_size)\n",
    "        \n",
    "        doc_vector[i, :] = word_vector\n",
    "\n",
    "    doc_vector = np.max(doc_vector, axis=0)\n",
    "    return doc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad91b268d7f4970ac16c55ea4886ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(roomba_df), model_w2v.wv.vector_size))\n",
    "\n",
    "for i, doc in tqdm_notebook(enumerate(roomba_df.wakati_text.values)):\n",
    "    X[i, :] = get_doc_swem_max_vector(doc, model_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.644048\tvalid_0's binary_logloss: 0.795825\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.69743\tvalid_0's binary_logloss: 0.635734\n",
      "Accuracy is 0.627906976744186 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.69409\tvalid_0's binary_logloss: 0.73212\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.711663\tvalid_0's binary_logloss: 0.625126\n",
      "Accuracy is 0.6705426356589147 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.660809\tvalid_0's binary_logloss: 0.766551\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.686928\tvalid_0's binary_logloss: 0.640245\n",
      "Accuracy is 0.6550387596899225 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.688205\tvalid_0's binary_logloss: 0.728406\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.724093\tvalid_0's binary_logloss: 0.631711\n",
      "Accuracy is 0.6653696498054474 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.715295\tvalid_0's binary_logloss: 0.680642\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.725852\tvalid_0's binary_logloss: 0.615804\n",
      "Accuracy is 0.6653696498054474 \n",
      "\n",
      "Elapsed time is 0.4305276870727539.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['swem_max'], elapsed_times_dict['swem_max']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCDV -w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/nyk510/scdv-python/blob/master/src/create.py より引用、一部改変\n",
    "def create_document_vector(documents, w2t, n_embedding):\n",
    "    \"\"\"\n",
    "    学習済みの word topic vector と分かち書き済みの文章, 使用されている単語から\n",
    "    文章ベクトルを作成するメソッド.\n",
    "    Args:\n",
    "        documents(list[list[str]]):\n",
    "        w2t(dict): 単語 -> 埋め込み次元の dict\n",
    "        n_embedding(int):\n",
    "    Returns:\n",
    "        embedded document vector\n",
    "    \"\"\"\n",
    "    doc_vectors = []\n",
    "\n",
    "    for doc in documents:\n",
    "        vector_i = np.zeros(shape=(n_embedding,))\n",
    "        for w in doc:\n",
    "            try:\n",
    "                v = w2t[w]\n",
    "                vector_i += v\n",
    "            except KeyError:\n",
    "                continue\n",
    "        doc_vectors.append(vector_i)\n",
    "    return np.array(doc_vectors)\n",
    "\n",
    "def create_idf_dataframe(documents):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        documents(list[str]):\n",
    "    Returns(pd.DataFrame):\n",
    "    \"\"\"\n",
    "\n",
    "    d = defaultdict(int)\n",
    "\n",
    "    for doc in documents:\n",
    "        vocab_i = set(doc)\n",
    "        for w in list(vocab_i):\n",
    "            d[w] += 1\n",
    "\n",
    "    df_idf = pd.DataFrame()\n",
    "    df_idf['count'] = d.values()\n",
    "    df_idf['word'] = d.keys()\n",
    "    df_idf['idf'] = np.log(len(documents) / df_idf['count'])\n",
    "    return df_idf\n",
    "\n",
    "def compress_document_vector(doc_vector, p=.04):\n",
    "    v = np.copy(doc_vector)\n",
    "    vec_norm = np.linalg.norm(v, axis=1)\n",
    "    # zero divide しないように\n",
    "    vec_norm = np.where(vec_norm > 0, vec_norm, 1.)\n",
    "    v /= vec_norm[:, None]\n",
    "\n",
    "    a_min = v.min(axis=1).mean()\n",
    "    a_max = v.max(axis=1).mean()\n",
    "    threshold = (abs(a_min) + abs(a_max)) / 2. * p\n",
    "    v[abs(v) < threshold] = .0\n",
    "    return v\n",
    "\n",
    "def get_scdv(parsed_docs, word_vec=model_w2v, n_components=60, compress=True):\n",
    "\n",
    "    n_wv_embed = word_vec.vector_size\n",
    "\n",
    "    # w2v model と corpus の語彙集合を作成\n",
    "    vocab_model = set(k for k in word_vec.wv.vocab.keys())\n",
    "    vocab_docs = set([w for doc in parsed_docs for w in doc])\n",
    "    out_of_vocabs = len(vocab_docs) - len(vocab_docs & vocab_model)\n",
    "    print('out of vocabs: {out_of_vocabs}'.format(**locals()))\n",
    "\n",
    "    # 使う文章に入っているものだけ学習させるため共通集合を取得してその word vector を GMM の入力にする\n",
    "    use_words = list(vocab_docs & vocab_model)\n",
    "\n",
    "    # 使う単語分だけ word vector を取得. よって shape = (n_vocabs, n_wv_embed,)\n",
    "    use_word_vectors = np.array([word_vec[w] for w in use_words])\n",
    "\n",
    "    # 公式実装: https://github.com/dheeraj7596/SCDV/blob/master/20news/SCDV.py#L32 により tied で学習\n",
    "    # 共分散行列全部推定する必要が有るほど低次元ではないという判断?\n",
    "    # -> 多分各クラスの分散を共通化することで各クラスに所属するデータ数を揃えたいとうのがお気持ちっぽい\n",
    "    clf = GaussianMixture(n_components=n_components, covariance_type='tied', verbose=2)\n",
    "    clf.fit(use_word_vectors)\n",
    "\n",
    "    # word probs は各単語のクラスタへの割当確率なので shape = (n_vocabs, n_components,)\n",
    "    word_probs = clf.predict_proba(use_word_vectors)\n",
    "\n",
    "    # 単語ごとにクラスタへの割当確率を wv に対して掛け算する\n",
    "    # shape = (n_vocabs, n_components, n_wv_embed) になる\n",
    "    word_cluster_vector = use_word_vectors[:, None, :] * word_probs[:, :, None]\n",
    "\n",
    "    # はじめに文章全体の idf を作成した後, use_word だけの df と left join して\n",
    "    # 使用している単語の idf を取得\n",
    "    df_use = pd.DataFrame()\n",
    "    df_use['word'] = use_words\n",
    "    df_idf = create_idf_dataframe(parsed_docs)\n",
    "    df_use = pd.merge(df_use, df_idf, on='word', how='left')\n",
    "    idf = df_use['idf'].values\n",
    "\n",
    "    # topic vector を計算するときに concatenation するとあるが\n",
    "    # 単に 二次元のベクトルに変形して各 vocab に対して idf をかければ OK\n",
    "    topic_vector = word_cluster_vector.reshape(-1, n_components * n_wv_embed) * idf[:, None]\n",
    "    # nanで影響が出ないように 0 で埋める\n",
    "    topic_vector[np.isnan(topic_vector)] = 0\n",
    "    word_to_topic = dict(zip(use_words, topic_vector))\n",
    "\n",
    "    n_embedding = topic_vector.shape[1]\n",
    "\n",
    "    cdv_vector = create_document_vector(parsed_docs, word_to_topic, n_embedding)\n",
    "    if compress:\n",
    "        compressed = compress_document_vector(cdv_vector)\n",
    "        return compressed\n",
    "    else:\n",
    "        return cdv_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of vocabs: 1535\n",
      "Initialization 0\n",
      "Initialization converged: True\t time lapse 0.03726s\t ll 1768.58434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:73: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "X = get_scdv(roomba_df.wakati_text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 18000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.693247\tvalid_0's binary_logloss: 0.736588\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.697159\tvalid_0's binary_logloss: 0.635992\n",
      "Accuracy is 0.6550387596899225 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.652985\tvalid_0's binary_logloss: 0.832846\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.660538\tvalid_0's binary_logloss: 0.653324\n",
      "Accuracy is 0.5968992248062015 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.711874\tvalid_0's binary_logloss: 0.683685\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.724633\tvalid_0's binary_logloss: 0.609547\n",
      "Accuracy is 0.6821705426356589 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.743993\tvalid_0's binary_logloss: 0.629808\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.752366\tvalid_0's binary_logloss: 0.585787\n",
      "Accuracy is 0.6926070038910506 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.691664\tvalid_0's binary_logloss: 0.716376\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.718086\tvalid_0's binary_logloss: 0.618938\n",
      "Accuracy is 0.6653696498054474 \n",
      "\n",
      "Elapsed time is 66.50248193740845.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['scdv_w2v'], elapsed_times_dict['scdv_w2v']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(roomba_df.wakati_text.values)]\n",
    "model = Doc2Vec(vector_size=300)\n",
    "model.build_vocab(corpus)\n",
    "model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([model.infer_vector(doc.split()) for doc in roomba_df.wakati_text.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 300)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.475806\tvalid_0's binary_logloss: 0.91858\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5263\tvalid_0's binary_logloss: 0.691946\n",
      "Accuracy is 0.5232558139534884 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.462085\tvalid_0's binary_logloss: 0.883262\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.606674\tvalid_0's binary_logloss: 0.682403\n",
      "Accuracy is 0.6046511627906976 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.472015\tvalid_0's binary_logloss: 0.881163\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.536471\tvalid_0's binary_logloss: 0.691915\n",
      "Accuracy is 0.5193798449612403 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.528637\tvalid_0's binary_logloss: 0.834033\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.485681\tvalid_0's binary_logloss: 0.693938\n",
      "Accuracy is 0.5214007782101168 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.506917\tvalid_0's binary_logloss: 0.868227\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.500334\tvalid_0's binary_logloss: 0.693379\n",
      "Accuracy is 0.5291828793774319 \n",
      "\n",
      "Elapsed time is 2.953019142150879.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['d2v_default'], elapsed_times_dict['d2v_default']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec - Epochs30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(roomba_df.wakati_text.values)]\n",
    "model = Doc2Vec(vector_size=300)\n",
    "model.build_vocab(corpus)\n",
    "model.train(corpus, total_examples=model.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([model.infer_vector(doc.split()) for doc in roomba_df.wakati_text.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 300)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.690299\tvalid_0's binary_logloss: 0.815305\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.678021\tvalid_0's binary_logloss: 0.646876\n",
      "Accuracy is 0.6395348837209303 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.66117\tvalid_0's binary_logloss: 0.823108\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.652383\tvalid_0's binary_logloss: 0.658736\n",
      "Accuracy is 0.6201550387596899 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.741213\tvalid_0's binary_logloss: 0.670422\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.747292\tvalid_0's binary_logloss: 0.602455\n",
      "Accuracy is 0.6744186046511628 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.695122\tvalid_0's binary_logloss: 0.772082\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.688448\tvalid_0's binary_logloss: 0.638058\n",
      "Accuracy is 0.6186770428015564 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.646705\tvalid_0's binary_logloss: 0.882306\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.612881\tvalid_0's binary_logloss: 0.673747\n",
      "Accuracy is 0.5836575875486382 \n",
      "\n",
      "Elapsed time is 3.578934907913208.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['d2v_epochs30'], elapsed_times_dict['d2v_epochs30']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec -mean -pretrained fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.keyedvectors as keyedvectors\n",
    "model_fasttext = keyedvectors.KeyedVectors.load_word2vec_format('../model/fasttext.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3026cfd37d034ada890d10fad0889be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(roomba_df), model_fasttext.wv.vector_size))\n",
    "\n",
    "for i, doc in tqdm_notebook(enumerate(roomba_df.wakati_text.values)):\n",
    "    X[i, :] = get_doc_mean_vector(doc, model_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 300)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.852792\tvalid_0's binary_logloss: 0.501117\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.846112\tvalid_0's binary_logloss: 0.483581\n",
      "Accuracy is 0.7596899224806202 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.861278\tvalid_0's binary_logloss: 0.48214\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.850927\tvalid_0's binary_logloss: 0.480044\n",
      "Accuracy is 0.7751937984496124 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.872232\tvalid_0's binary_logloss: 0.453854\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.87157\tvalid_0's binary_logloss: 0.451187\n",
      "Accuracy is 0.7984496124031008 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.854933\tvalid_0's binary_logloss: 0.48944\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.857056\tvalid_0's binary_logloss: 0.470438\n",
      "Accuracy is 0.7937743190661478 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.864883\tvalid_0's binary_logloss: 0.479766\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.862031\tvalid_0's binary_logloss: 0.461887\n",
      "Accuracy is 0.7587548638132295 \n",
      "\n",
      "Elapsed time is 4.93558669090271.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['fasttext_mean'], elapsed_times_dict['fasttext_mean']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWEM -MAX -pretraned fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1488dc4575e3407e98bc21ed74410fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(roomba_df), model_fasttext.wv.vector_size))\n",
    "\n",
    "for i, doc in tqdm_notebook(enumerate(roomba_df.wakati_text.values)):\n",
    "    X[i, :] = get_doc_swem_max_vector(doc, model_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 300)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.834015\tvalid_0's binary_logloss: 0.524641\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.83558\tvalid_0's binary_logloss: 0.495617\n",
      "Accuracy is 0.7751937984496124 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.866514\tvalid_0's binary_logloss: 0.48406\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.867176\tvalid_0's binary_logloss: 0.458468\n",
      "Accuracy is 0.7945736434108527 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.873736\tvalid_0's binary_logloss: 0.461715\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.872232\tvalid_0's binary_logloss: 0.444634\n",
      "Accuracy is 0.7751937984496124 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.826781\tvalid_0's binary_logloss: 0.573995\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.815071\tvalid_0's binary_logloss: 0.533696\n",
      "Accuracy is 0.7237354085603113 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.868766\tvalid_0's binary_logloss: 0.465423\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.868645\tvalid_0's binary_logloss: 0.449834\n",
      "Accuracy is 0.7704280155642024 \n",
      "\n",
      "Elapsed time is 3.8937463760375977.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['swem_max_fasttext'], elapsed_times_dict['swem_max_fasttext']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCDV -pretrained fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of vocabs: 139\n",
      "Initialization 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration 10\t time lapse 1.34112s\t ll change 0.01142\n",
      "Initialization converged: True\t time lapse 1.83151s\t ll 54.34123\n"
     ]
    }
   ],
   "source": [
    "X = get_scdv(roomba_df.wakati_text.values, word_vec=model_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 18000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.815961\tvalid_0's binary_logloss: 0.5912\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.827215\tvalid_0's binary_logloss: 0.512622\n",
      "Accuracy is 0.751937984496124 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.856103\tvalid_0's binary_logloss: 0.513851\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.863746\tvalid_0's binary_logloss: 0.471718\n",
      "Accuracy is 0.7751937984496124 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.792549\tvalid_0's binary_logloss: 0.661613\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.779911\tvalid_0's binary_logloss: 0.571151\n",
      "Accuracy is 0.7015503875968992 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.854265\tvalid_0's binary_logloss: 0.519531\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.850504\tvalid_0's binary_logloss: 0.486384\n",
      "Accuracy is 0.7587548638132295 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.799782\tvalid_0's binary_logloss: 0.610978\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.788921\tvalid_0's binary_logloss: 0.554548\n",
      "Accuracy is 0.7159533073929961 \n",
      "\n",
      "Elapsed time is 52.75395083427429.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['scdv_fasttext'], elapsed_times_dict['scdv_fasttext']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCDV -pretrained fastText -raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of vocabs: 139\n",
      "Initialization 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration 10\t time lapse 1.37528s\t ll change 0.00694\n",
      "  Iteration 20\t time lapse 1.24726s\t ll change 0.00184\n",
      "Initialization converged: True\t time lapse 2.74699s\t ll 53.99191\n"
     ]
    }
   ],
   "source": [
    "X = get_scdv(roomba_df.wakati_text.values, word_vec=model_fasttext, compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 18000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.820896\tvalid_0's binary_logloss: 0.599928\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.810123\tvalid_0's binary_logloss: 0.531217\n",
      "Accuracy is 0.7325581395348837 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.857667\tvalid_0's binary_logloss: 0.515166\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.856103\tvalid_0's binary_logloss: 0.478357\n",
      "Accuracy is 0.7868217054263565 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.789661\tvalid_0's binary_logloss: 0.674258\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.767935\tvalid_0's binary_logloss: 0.583191\n",
      "Accuracy is 0.7015503875968992 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.845589\tvalid_0's binary_logloss: 0.560654\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.822958\tvalid_0's binary_logloss: 0.522093\n",
      "Accuracy is 0.7276264591439688 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.822412\tvalid_0's binary_logloss: 0.60868\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.792319\tvalid_0's binary_logloss: 0.553444\n",
      "Accuracy is 0.6964980544747081 \n",
      "\n",
      "Elapsed time is 121.901780128479.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['scdv_fasttext_raw'], elapsed_times_dict['scdv_fasttext_raw']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCDV -w2v -raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of vocabs: 139\n",
      "Initialization 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration 10\t time lapse 1.31958s\t ll change 0.00499\n",
      "Initialization converged: True\t time lapse 1.56046s\t ll 55.00013\n"
     ]
    }
   ],
   "source": [
    "X = get_scdv(roomba_df.wakati_text.values, word_vec=model_fasttext, compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 18000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.854538\tvalid_0's binary_logloss: 0.516207\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.860014\tvalid_0's binary_logloss: 0.477282\n",
      "Accuracy is 0.7945736434108527 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.851709\tvalid_0's binary_logloss: 0.546184\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.836844\tvalid_0's binary_logloss: 0.509116\n",
      "Accuracy is 0.7403100775193798 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.797665\tvalid_0's binary_logloss: 0.644748\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.781054\tvalid_0's binary_logloss: 0.561\n",
      "Accuracy is 0.7015503875968992 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.821745\tvalid_0's binary_logloss: 0.635957\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.81137\tvalid_0's binary_logloss: 0.539749\n",
      "Accuracy is 0.7392996108949417 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.812462\tvalid_0's binary_logloss: 0.624006\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.784007\tvalid_0's binary_logloss: 0.561896\n",
      "Accuracy is 0.7276264591439688 \n",
      "\n",
      "Elapsed time is 212.78524160385132.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['scdv_w2v_raw'], elapsed_times_dict['scdv_w2v_raw']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [accs_dict, elapsed_times_dict]\n",
    "pd.to_pickle(results, '../data/results_roomba.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
