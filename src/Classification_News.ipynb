{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import MeCab\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from gensim.models import word2vec\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm, tqdm_pandas, tqdm_notebook\n",
    "import time\n",
    "tqdm.pandas(tqdm_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('../data/news.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie-enter</td>\n",
       "      <td>【DVDエンター！】誘拐犯に育てられた女が目にした真実は、孤独か幸福か2005年11月から翌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie-enter</td>\n",
       "      <td>藤原竜也、中学生とともにロケット打ち上げに成功「アンテナを張りながら生活をしていけばいい」2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie-enter</td>\n",
       "      <td>『戦火の馬』ロイヤル・プレミアにウィリアム王子＆キャサリン妃が出席3月2日より全国ロードショ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie-enter</td>\n",
       "      <td>香里奈、女子高生100人のガチンコ質問に回答「ラーメンも食べる」女優の香里奈が18日、都内で...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie-enter</td>\n",
       "      <td>ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」5日、東京・千代田区の内幸町...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "0  movie-enter  【DVDエンター！】誘拐犯に育てられた女が目にした真実は、孤独か幸福か2005年11月から翌...\n",
       "1  movie-enter  藤原竜也、中学生とともにロケット打ち上げに成功「アンテナを張りながら生活をしていけばいい」2...\n",
       "2  movie-enter  『戦火の馬』ロイヤル・プレミアにウィリアム王子＆キャサリン妃が出席3月2日より全国ロードショ...\n",
       "3  movie-enter  香里奈、女子高生100人のガチンコ質問に回答「ラーメンも食べる」女優の香里奈が18日、都内で...\n",
       "4  movie-enter  ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」5日、東京・千代田区の内幸町..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sports-watch      900\n",
       "dokujo-tsushin    870\n",
       "movie-enter       870\n",
       "smax              870\n",
       "it-life-hack      870\n",
       "kaden-channel     864\n",
       "peachy            842\n",
       "topic-news        770\n",
       "livedoor-homme    511\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wakati_text(text):\n",
    "    tagger = MeCab.Tagger('-Owakati')\n",
    "    wakati_text = tagger.parse(text).strip()\n",
    "    return wakati_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7367/7367 [00:07<00:00, 964.30it/s] \n"
     ]
    }
   ],
   "source": [
    "news_df['wakati_text'] = news_df.text.progress_apply(get_wakati_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>wakati_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie-enter</td>\n",
       "      <td>【DVDエンター！】誘拐犯に育てられた女が目にした真実は、孤独か幸福か2005年11月から翌...</td>\n",
       "      <td>【 DVD エンター ！ 】 誘拐 犯 に 育て られ た 女 が 目 に し た 真実 は...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie-enter</td>\n",
       "      <td>藤原竜也、中学生とともにロケット打ち上げに成功「アンテナを張りながら生活をしていけばいい」2...</td>\n",
       "      <td>藤原 竜也 、 中学生 とともに ロケット 打ち上げ に 成功 「 アンテナ を 張り なが...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie-enter</td>\n",
       "      <td>『戦火の馬』ロイヤル・プレミアにウィリアム王子＆キャサリン妃が出席3月2日より全国ロードショ...</td>\n",
       "      <td>『 戦火 の 馬 』 ロイヤル ・ プレミア に ウィリアム 王子 ＆ キャサリン 妃 が ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie-enter</td>\n",
       "      <td>香里奈、女子高生100人のガチンコ質問に回答「ラーメンも食べる」女優の香里奈が18日、都内で...</td>\n",
       "      <td>香里奈 、 女子高 生 100 人 の ガチンコ 質問 に 回答 「 ラーメン も 食べる ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie-enter</td>\n",
       "      <td>ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」5日、東京・千代田区の内幸町...</td>\n",
       "      <td>ユージ の 前 に 立ちはだかっ た JOY 「 僕 は AKB の 高橋 みなみ を 守る...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text  \\\n",
       "0  movie-enter  【DVDエンター！】誘拐犯に育てられた女が目にした真実は、孤独か幸福か2005年11月から翌...   \n",
       "1  movie-enter  藤原竜也、中学生とともにロケット打ち上げに成功「アンテナを張りながら生活をしていけばいい」2...   \n",
       "2  movie-enter  『戦火の馬』ロイヤル・プレミアにウィリアム王子＆キャサリン妃が出席3月2日より全国ロードショ...   \n",
       "3  movie-enter  香里奈、女子高生100人のガチンコ質問に回答「ラーメンも食べる」女優の香里奈が18日、都内で...   \n",
       "4  movie-enter  ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」5日、東京・千代田区の内幸町...   \n",
       "\n",
       "                                         wakati_text  \n",
       "0  【 DVD エンター ！ 】 誘拐 犯 に 育て られ た 女 が 目 に し た 真実 は...  \n",
       "1  藤原 竜也 、 中学生 とともに ロケット 打ち上げ に 成功 「 アンテナ を 張り なが...  \n",
       "2  『 戦火 の 馬 』 ロイヤル ・ プレミア に ウィリアム 王子 ＆ キャサリン 妃 が ...  \n",
       "3  香里奈 、 女子高 生 100 人 の ガチンコ 質問 に 回答 「 ラーメン も 食べる ...  \n",
       "4  ユージ の 前 に 立ちはだかっ た JOY 「 僕 は AKB の 高橋 みなみ を 守る...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = news_df.label.values\n",
    "accs_dict = {}\n",
    "elapsed_times_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_get_oof_accuracies(X, y, params):\n",
    "    START_TIME = time.time()\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    accuracies = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
    "        print(f'Start: fold {i+1}')\n",
    "        X_train, y_train = X[train_index, :], y[train_index]\n",
    "        X_valid, y_valid = X[valid_index, :], y[valid_index]\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=(X_valid, y_valid),\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=100\n",
    "        )\n",
    "        y_pred = model.predict(X_valid)\n",
    "        accuracy = accuracy_score(y_valid, y_pred)\n",
    "        print(f'Accuracy is {accuracy} \\n')\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    elapsed_time = time.time() - START_TIME\n",
    "    print(f'Elapsed time is {elapsed_time}.')\n",
    "    return accuracies, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': news_df.label.nunique(),\n",
    "    'n_estimators': 10000,\n",
    "    'random_seed': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "X = vectorizer.fit_transform(news_df.wakati_text.values)\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 71646)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.159019\n",
      "[200]\tvalid_0's multi_logloss: 0.173628\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's multi_logloss: 0.156125\n",
      "Accuracy is 0.9525423728813559 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.148067\n",
      "[200]\tvalid_0's multi_logloss: 0.157974\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's multi_logloss: 0.144632\n",
      "Accuracy is 0.9572591587516961 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.125745\n",
      "[200]\tvalid_0's multi_logloss: 0.122956\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 0.118081\n",
      "Accuracy is 0.9640190088255262 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.129558\n",
      "[200]\tvalid_0's multi_logloss: 0.143817\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.127086\n",
      "Accuracy is 0.9640190088255262 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.134151\n",
      "[200]\tvalid_0's multi_logloss: 0.142602\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's multi_logloss: 0.130477\n",
      "Accuracy is 0.9599184782608695 \n",
      "\n",
      "Elapsed time is 119.94863891601562.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['bow'], elapsed_times_dict['bow'] = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW+TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd = TruncatedSVD(n_components=100)\n",
    "X_reduced = tsvd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.427786\n",
      "[200]\tvalid_0's multi_logloss: 0.431585\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's multi_logloss: 0.408679\n",
      "Accuracy is 0.8738983050847458 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.424189\n",
      "[200]\tvalid_0's multi_logloss: 0.408522\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's multi_logloss: 0.399322\n",
      "Accuracy is 0.8772048846675712 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.411262\n",
      "[200]\tvalid_0's multi_logloss: 0.398127\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's multi_logloss: 0.387545\n",
      "Accuracy is 0.8750848608282417 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.404523\n",
      "[200]\tvalid_0's multi_logloss: 0.408925\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's multi_logloss: 0.390372\n",
      "Accuracy is 0.8879837067209776 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.427535\n",
      "[200]\tvalid_0's multi_logloss: 0.419641\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's multi_logloss: 0.405714\n",
      "Accuracy is 0.8783967391304348 \n",
      "\n",
      "Elapsed time is 38.25342154502869.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['bow_tsvd'], elapsed_times_dict['bow_tsvd'] = train_and_get_oof_accuracies(X_reduced, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True, token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "X = vectorizer.fit_transform(news_df.wakati_text.values)\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 71646)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.168869\n",
      "[200]\tvalid_0's multi_logloss: 0.189717\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's multi_logloss: 0.168724\n",
      "Accuracy is 0.9491525423728814 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.164664\n",
      "[200]\tvalid_0's multi_logloss: 0.180684\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 0.163739\n",
      "Accuracy is 0.9497964721845319 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.145545\n",
      "[200]\tvalid_0's multi_logloss: 0.145236\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's multi_logloss: 0.141311\n",
      "Accuracy is 0.9599456890699253 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.140006\n",
      "[200]\tvalid_0's multi_logloss: 0.162954\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's multi_logloss: 0.139152\n",
      "Accuracy is 0.957909029192125 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.149432\n",
      "[200]\tvalid_0's multi_logloss: 0.17345\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's multi_logloss: 0.148391\n",
      "Accuracy is 0.953125 \n",
      "\n",
      "Elapsed time is 285.5730438232422.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['tfidf'], elapsed_times_dict['tfidf'] = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF+TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd = TruncatedSVD(n_components=100)\n",
    "X_reduced = tsvd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.270505\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_logloss: 0.268477\n",
      "Accuracy is 0.9159322033898305 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.305707\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's multi_logloss: 0.300025\n",
      "Accuracy is 0.9063772048846676 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.32101\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's multi_logloss: 0.319156\n",
      "Accuracy is 0.8934147997284454 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.296192\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 0.291762\n",
      "Accuracy is 0.9124236252545825 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.262702\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's multi_logloss: 0.26112\n",
      "Accuracy is 0.9211956521739131 \n",
      "\n",
      "Elapsed time is 26.106940031051636.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['tfidf_tsvd'], elapsed_times_dict['tfidf_tsvd']  = train_and_get_oof_accuracies(X_reduced, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec -mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [doc.split() for doc in news_df.wakati_text.values]\n",
    "model_w2v = word2vec.Word2Vec(corpus, size=300, min_count=20, window=10)\n",
    "model_w2v.save('../model/news_w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_mean_vector(doc, model):\n",
    "    doc_vector = np.zeros(model.vector_size)\n",
    "    words = doc.split()\n",
    "    word_cnt = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_vector = model.wv[word]\n",
    "            doc_vector += word_vector\n",
    "            word_cnt += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "    doc_vector /= word_cnt\n",
    "    return doc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d96dd6923441d5b7e8348d09ece654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(news_df), model_w2v.wv.vector_size))\n",
    "\n",
    "for i, doc in tqdm_notebook(enumerate(news_df.wakati_text.values)):\n",
    "    X[i, :] = get_doc_mean_vector(doc, model_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.349747\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's multi_logloss: 0.348576\n",
      "Accuracy is 0.8888135593220339 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.324592\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_logloss: 0.323728\n",
      "Accuracy is 0.8955223880597015 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.370943\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's multi_logloss: 0.367494\n",
      "Accuracy is 0.8839103869653768 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.329032\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's multi_logloss: 0.326502\n",
      "Accuracy is 0.9049558723693143 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.342435\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's multi_logloss: 0.340837\n",
      "Accuracy is 0.8899456521739131 \n",
      "\n",
      "Elapsed time is 72.10090398788452.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['w2v_mean'], elapsed_times_dict['w2v_mean']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWEM-MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_swem_max_vector(doc, model):\n",
    "    words = doc.split()\n",
    "    word_cnt = 0\n",
    "    vector_size = model.vector_size\n",
    "    \n",
    "    doc_vector = np.zeros((len(words), vector_size))\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        try:\n",
    "            word_vector = model.wv[word]\n",
    "        except KeyError:\n",
    "            word_vector = np.zeros(vector_size)\n",
    "        \n",
    "        doc_vector[i, :] = word_vector\n",
    "\n",
    "    doc_vector = np.max(doc_vector, axis=0)\n",
    "    return doc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafc8ed04cbe40cbadf5ac951ac78df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(news_df), model_w2v.wv.vector_size))\n",
    "\n",
    "for i, doc in tqdm_notebook(enumerate(news_df.wakati_text.values)):\n",
    "    X[i, :] = get_doc_swem_max_vector(doc, model_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.252278\n",
      "[200]\tvalid_0's multi_logloss: 0.282172\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.250547\n",
      "Accuracy is 0.9179661016949152 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.303795\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 0.303722\n",
      "Accuracy is 0.9077340569877883 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.290364\n",
      "[200]\tvalid_0's multi_logloss: 0.318144\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's multi_logloss: 0.288602\n",
      "Accuracy is 0.9137813985064495 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.252443\n",
      "[200]\tvalid_0's multi_logloss: 0.286379\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 0.251445\n",
      "Accuracy is 0.9300746775288526 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.243245\n",
      "[200]\tvalid_0's multi_logloss: 0.271738\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's multi_logloss: 0.239859\n",
      "Accuracy is 0.9157608695652174 \n",
      "\n",
      "Elapsed time is 17.454517602920532.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['swem_max'], elapsed_times_dict['swem_max']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCDV -w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/nyk510/scdv-python/blob/master/src/create.py より引用、一部改変\n",
    "def create_document_vector(documents, w2t, n_embedding):\n",
    "    \"\"\"\n",
    "    学習済みの word topic vector と分かち書き済みの文章, 使用されている単語から\n",
    "    文章ベクトルを作成するメソッド.\n",
    "    Args:\n",
    "        documents(list[list[str]]):\n",
    "        w2t(dict): 単語 -> 埋め込み次元の dict\n",
    "        n_embedding(int):\n",
    "    Returns:\n",
    "        embedded document vector\n",
    "    \"\"\"\n",
    "    doc_vectors = []\n",
    "\n",
    "    for doc in documents:\n",
    "        vector_i = np.zeros(shape=(n_embedding,))\n",
    "        for w in doc:\n",
    "            try:\n",
    "                v = w2t[w]\n",
    "                vector_i += v\n",
    "            except KeyError:\n",
    "                continue\n",
    "        doc_vectors.append(vector_i)\n",
    "    return np.array(doc_vectors)\n",
    "\n",
    "def create_idf_dataframe(documents):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        documents(list[str]):\n",
    "    Returns(pd.DataFrame):\n",
    "    \"\"\"\n",
    "\n",
    "    d = defaultdict(int)\n",
    "\n",
    "    for doc in documents:\n",
    "        vocab_i = set(doc)\n",
    "        for w in list(vocab_i):\n",
    "            d[w] += 1\n",
    "\n",
    "    df_idf = pd.DataFrame()\n",
    "    df_idf['count'] = d.values()\n",
    "    df_idf['word'] = d.keys()\n",
    "    df_idf['idf'] = np.log(len(documents) / df_idf['count'])\n",
    "    return df_idf\n",
    "\n",
    "def compress_document_vector(doc_vector, p=.04):\n",
    "    v = np.copy(doc_vector)\n",
    "    vec_norm = np.linalg.norm(v, axis=1)\n",
    "    # zero divide しないように\n",
    "    vec_norm = np.where(vec_norm > 0, vec_norm, 1.)\n",
    "    v /= vec_norm[:, None]\n",
    "\n",
    "    a_min = v.min(axis=1).mean()\n",
    "    a_max = v.max(axis=1).mean()\n",
    "    threshold = (abs(a_min) + abs(a_max)) / 2. * p\n",
    "    v[abs(v) < threshold] = .0\n",
    "    return v\n",
    "\n",
    "def get_scdv(parsed_docs, word_vec=model_w2v, n_components=60, compress=True):\n",
    "\n",
    "    n_wv_embed = word_vec.vector_size\n",
    "\n",
    "    # w2v model と corpus の語彙集合を作成\n",
    "    vocab_model = set(k for k in word_vec.wv.vocab.keys())\n",
    "    vocab_docs = set([w for doc in parsed_docs for w in doc])\n",
    "    out_of_vocabs = len(vocab_docs) - len(vocab_docs & vocab_model)\n",
    "    print('out of vocabs: {out_of_vocabs}'.format(**locals()))\n",
    "\n",
    "    # 使う文章に入っているものだけ学習させるため共通集合を取得してその word vector を GMM の入力にする\n",
    "    use_words = list(vocab_docs & vocab_model)\n",
    "\n",
    "    # 使う単語分だけ word vector を取得. よって shape = (n_vocabs, n_wv_embed,)\n",
    "    use_word_vectors = np.array([word_vec[w] for w in use_words])\n",
    "\n",
    "    # 公式実装: https://github.com/dheeraj7596/SCDV/blob/master/20news/SCDV.py#L32 により tied で学習\n",
    "    # 共分散行列全部推定する必要が有るほど低次元ではないという判断?\n",
    "    # -> 多分各クラスの分散を共通化することで各クラスに所属するデータ数を揃えたいとうのがお気持ちっぽい\n",
    "    clf = GaussianMixture(n_components=n_components, covariance_type='tied', verbose=2)\n",
    "    clf.fit(use_word_vectors)\n",
    "\n",
    "    # word probs は各単語のクラスタへの割当確率なので shape = (n_vocabs, n_components,)\n",
    "    word_probs = clf.predict_proba(use_word_vectors)\n",
    "\n",
    "    # 単語ごとにクラスタへの割当確率を wv に対して掛け算する\n",
    "    # shape = (n_vocabs, n_components, n_wv_embed) になる\n",
    "    word_cluster_vector = use_word_vectors[:, None, :] * word_probs[:, :, None]\n",
    "\n",
    "    # はじめに文章全体の idf を作成した後, use_word だけの df と left join して\n",
    "    # 使用している単語の idf を取得\n",
    "    df_use = pd.DataFrame()\n",
    "    df_use['word'] = use_words\n",
    "    df_idf = create_idf_dataframe(parsed_docs)\n",
    "    df_use = pd.merge(df_use, df_idf, on='word', how='left')\n",
    "    idf = df_use['idf'].values\n",
    "\n",
    "    # topic vector を計算するときに concatenation するとあるが\n",
    "    # 単に 二次元のベクトルに変形して各 vocab に対して idf をかければ OK\n",
    "    topic_vector = word_cluster_vector.reshape(-1, n_components * n_wv_embed) * idf[:, None]\n",
    "    # nanで影響が出ないように 0 で埋める\n",
    "    topic_vector[np.isnan(topic_vector)] = 0\n",
    "    word_to_topic = dict(zip(use_words, topic_vector))\n",
    "\n",
    "    n_embedding = topic_vector.shape[1]\n",
    "\n",
    "    cdv_vector = create_document_vector(parsed_docs, word_to_topic, n_embedding)\n",
    "    if compress:\n",
    "        compressed = compress_document_vector(cdv_vector)\n",
    "        return compressed\n",
    "    else:\n",
    "        return cdv_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of vocabs: 2567\n",
      "Initialization 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:73: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration 10\t time lapse 0.97443s\t ll change 0.02409\n",
      "Initialization converged: True\t time lapse 1.62653s\t ll 555.91177\n"
     ]
    }
   ],
   "source": [
    "X = get_scdv(news_df.wakati_text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 18000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.408476\n",
      "[200]\tvalid_0's multi_logloss: 0.455125\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 0.406118\n",
      "Accuracy is 0.8684745762711864 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.399024\n",
      "[200]\tvalid_0's multi_logloss: 0.433227\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's multi_logloss: 0.393422\n",
      "Accuracy is 0.8799185888738128 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.415187\n",
      "[200]\tvalid_0's multi_logloss: 0.455897\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's multi_logloss: 0.414618\n",
      "Accuracy is 0.86693822131704 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.354444\n",
      "[200]\tvalid_0's multi_logloss: 0.385248\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's multi_logloss: 0.351332\n",
      "Accuracy is 0.8981670061099797 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.381748\n",
      "[200]\tvalid_0's multi_logloss: 0.421634\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's multi_logloss: 0.378952\n",
      "Accuracy is 0.8790760869565217 \n",
      "\n",
      "Elapsed time is 2971.7359380722046.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['scdv_w2v'], elapsed_times_dict['scdv_w2v']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(news_df.wakati_text.values)]\n",
    "model = Doc2Vec(vector_size=300)\n",
    "model.build_vocab(corpus)\n",
    "model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([model.infer_vector(doc.split()) for doc in news_df.wakati_text.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 300)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.410166\n",
      "[200]\tvalid_0's multi_logloss: 0.438682\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's multi_logloss: 0.404398\n",
      "Accuracy is 0.8515254237288136 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.375066\n",
      "[200]\tvalid_0's multi_logloss: 0.397589\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's multi_logloss: 0.367302\n",
      "Accuracy is 0.8792401628222524 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.45298\n",
      "[200]\tvalid_0's multi_logloss: 0.496435\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 0.449182\n",
      "Accuracy is 0.8533604887983707 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.394936\n",
      "[200]\tvalid_0's multi_logloss: 0.421278\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's multi_logloss: 0.390176\n",
      "Accuracy is 0.8764426340801086 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.388316\n",
      "[200]\tvalid_0's multi_logloss: 0.410194\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's multi_logloss: 0.380114\n",
      "Accuracy is 0.8716032608695652 \n",
      "\n",
      "Elapsed time is 90.71377110481262.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['d2v_default'], elapsed_times_dict['d2v_default']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec - Epochs30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(news_df.wakati_text.values)]\n",
    "model = Doc2Vec(vector_size=300)\n",
    "model.build_vocab(corpus)\n",
    "model.train(corpus, total_examples=model.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([model.infer_vector(doc.split()) for doc in news_df.wakati_text.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 300)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.478027\n",
      "[200]\tvalid_0's multi_logloss: 0.394044\n",
      "[300]\tvalid_0's multi_logloss: 0.414963\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's multi_logloss: 0.391872\n",
      "Accuracy is 0.8745762711864407 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.437851\n",
      "[200]\tvalid_0's multi_logloss: 0.340627\n",
      "[300]\tvalid_0's multi_logloss: 0.345039\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's multi_logloss: 0.337321\n",
      "Accuracy is 0.8914518317503393 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.452152\n",
      "[200]\tvalid_0's multi_logloss: 0.358036\n",
      "[300]\tvalid_0's multi_logloss: 0.369286\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's multi_logloss: 0.356541\n",
      "Accuracy is 0.8805159538357095 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.437499\n",
      "[200]\tvalid_0's multi_logloss: 0.352738\n",
      "[300]\tvalid_0's multi_logloss: 0.365206\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's multi_logloss: 0.349682\n",
      "Accuracy is 0.891378139850645 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.462631\n",
      "[200]\tvalid_0's multi_logloss: 0.382527\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's multi_logloss: 0.382516\n",
      "Accuracy is 0.876358695652174 \n",
      "\n",
      "Elapsed time is 126.87824606895447.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['d2v_epochs30'], elapsed_times_dict['d2v_epochs30']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec -mean -pretrained fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.keyedvectors as keyedvectors\n",
    "model_fasttext = keyedvectors.KeyedVectors.load_word2vec_format('../model/fasttext.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed93539925d44000b78bcfb837efbcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(news_df), model_fasttext.wv.vector_size))\n",
    "\n",
    "for i, doc in tqdm_notebook(enumerate(news_df.wakati_text.values)):\n",
    "    X[i, :] = get_doc_mean_vector(doc, model_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 300)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.411041\n",
      "[200]\tvalid_0's multi_logloss: 0.481018\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's multi_logloss: 0.410916\n",
      "Accuracy is 0.8671186440677966 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.36119\n",
      "[200]\tvalid_0's multi_logloss: 0.402293\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's multi_logloss: 0.359622\n",
      "Accuracy is 0.8853459972862958 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.43532\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's multi_logloss: 0.434781\n",
      "Accuracy is 0.858112695179905 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.365556\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's multi_logloss: 0.364605\n",
      "Accuracy is 0.879837067209776 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.356507\n",
      "[200]\tvalid_0's multi_logloss: 0.393635\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.353671\n",
      "Accuracy is 0.889266304347826 \n",
      "\n",
      "Elapsed time is 79.51075530052185.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['fasttext_mean'], elapsed_times_dict['fasttext_mean']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWEM -MAX -pretraned fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db0801047c44430aa88a8a67949b4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(news_df), model_fasttext.wv.vector_size))\n",
    "\n",
    "for i, doc in tqdm_notebook(enumerate(news_df.wakati_text.values)):\n",
    "    X[i, :] = get_doc_swem_max_vector(doc, model_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 300)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.27356\n",
      "[200]\tvalid_0's multi_logloss: 0.273228\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's multi_logloss: 0.260954\n",
      "Accuracy is 0.9138983050847458 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.286736\n",
      "[200]\tvalid_0's multi_logloss: 0.286457\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's multi_logloss: 0.275669\n",
      "Accuracy is 0.9158751696065129 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.287594\n",
      "[200]\tvalid_0's multi_logloss: 0.275379\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's multi_logloss: 0.268537\n",
      "Accuracy is 0.911744738628649 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.293082\n",
      "[200]\tvalid_0's multi_logloss: 0.296688\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's multi_logloss: 0.284888\n",
      "Accuracy is 0.9131025118805159 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.265246\n",
      "[200]\tvalid_0's multi_logloss: 0.265006\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's multi_logloss: 0.25424\n",
      "Accuracy is 0.9116847826086957 \n",
      "\n",
      "Elapsed time is 84.86075592041016.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['swem_max_fasttext'], elapsed_times_dict['swem_max_fasttext']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCDV -pretrained fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of vocabs: 463\n",
      "Initialization 0\n",
      "  Iteration 10\t time lapse 3.31651s\t ll change 0.00775\n",
      "  Iteration 20\t time lapse 3.05870s\t ll change 0.00595\n",
      "Initialization converged: True\t time lapse 7.90065s\t ll 23.37736\n"
     ]
    }
   ],
   "source": [
    "X = get_scdv(news_df.wakati_text.values, word_vec=model_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 18000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.402941\n",
      "[200]\tvalid_0's multi_logloss: 0.448402\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's multi_logloss: 0.398791\n",
      "Accuracy is 0.8772881355932204 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.405631\n",
      "[200]\tvalid_0's multi_logloss: 0.447015\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.403606\n",
      "Accuracy is 0.878561736770692 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.427582\n",
      "[200]\tvalid_0's multi_logloss: 0.473779\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's multi_logloss: 0.422557\n",
      "Accuracy is 0.8737270875763747 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.380217\n",
      "[200]\tvalid_0's multi_logloss: 0.422549\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.37349\n",
      "Accuracy is 0.8906992532247114 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.367811\n",
      "[200]\tvalid_0's multi_logloss: 0.403988\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 0.366884\n",
      "Accuracy is 0.8824728260869565 \n",
      "\n",
      "Elapsed time is 3519.537034034729.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['scdv_fasttext'], elapsed_times_dict['scdv_fasttext']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCDV - pretrained fastText -raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of vocabs: 463\n",
      "Initialization 0\n",
      "  Iteration 10\t time lapse 3.28870s\t ll change 0.01126\n",
      "  Iteration 20\t time lapse 3.05809s\t ll change 0.00252\n",
      "Initialization converged: True\t time lapse 6.65311s\t ll 23.50536\n"
     ]
    }
   ],
   "source": [
    "X = get_scdv(news_df.wakati_text.values, word_vec=model_fasttext, compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 18000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.302716\n",
      "[200]\tvalid_0's multi_logloss: 0.33929\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's multi_logloss: 0.301412\n",
      "Accuracy is 0.9064406779661017 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.257149\n",
      "[200]\tvalid_0's multi_logloss: 0.283197\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's multi_logloss: 0.254539\n",
      "Accuracy is 0.9219810040705563 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.279389\n",
      "[200]\tvalid_0's multi_logloss: 0.296254\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's multi_logloss: 0.277186\n",
      "Accuracy is 0.9205702647657841 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.273663\n",
      "[200]\tvalid_0's multi_logloss: 0.298073\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 0.271395\n",
      "Accuracy is 0.9205702647657841 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.255283\n",
      "[200]\tvalid_0's multi_logloss: 0.269838\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 0.249513\n",
      "Accuracy is 0.9245923913043478 \n",
      "\n",
      "Elapsed time is 4616.114170074463.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['scdv_fasttext_raw'], elapsed_times_dict['scdv_fasttext_raw']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCDV -w2v -raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of vocabs: 2567\n",
      "Initialization 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:73: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration 10\t time lapse 1.10014s\t ll change 0.00740\n",
      "Initialization converged: True\t time lapse 1.42006s\t ll 556.31595\n"
     ]
    }
   ],
   "source": [
    "X = get_scdv(news_df.wakati_text.values, word_vec=model_w2v, compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 18000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.331121\n",
      "[200]\tvalid_0's multi_logloss: 0.364291\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's multi_logloss: 0.328557\n",
      "Accuracy is 0.8969491525423728 \n",
      "\n",
      "Start: fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.316796\n",
      "[200]\tvalid_0's multi_logloss: 0.343936\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's multi_logloss: 0.311626\n",
      "Accuracy is 0.8989145183175034 \n",
      "\n",
      "Start: fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.329839\n",
      "[200]\tvalid_0's multi_logloss: 0.360964\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.326948\n",
      "Accuracy is 0.8906992532247114 \n",
      "\n",
      "Start: fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.283325\n",
      "[200]\tvalid_0's multi_logloss: 0.311122\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's multi_logloss: 0.281045\n",
      "Accuracy is 0.9178547182620502 \n",
      "\n",
      "Start: fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.302535\n",
      "[200]\tvalid_0's multi_logloss: 0.333334\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's multi_logloss: 0.298851\n",
      "Accuracy is 0.9021739130434783 \n",
      "\n",
      "Elapsed time is 2939.0836856365204.\n"
     ]
    }
   ],
   "source": [
    "accs_dict['scdv_w2v_raw'], elapsed_times_dict['scdv_w2v_raw']  = train_and_get_oof_accuracies(X, y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [accs_dict, elapsed_times_dict]\n",
    "pd.to_pickle(results, '../data/results_news.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
